{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea216028-c63b-4365-ba9e-6d44e1d9e118",
   "metadata": {},
   "source": [
    "## Example 3: Building Conversational Chains (Messages and Tools)\n",
    "\n",
    "Building sophisticated agents that can handle conversations and using tools. \n",
    "\n",
    "Reference: [Getting Started with LangGraph: A Beginner’s Guide to Building Intelligent Workflows](https://medium.com/@ashutoshsharmaengg/getting-started-with-langgraph-a-beginners-guide-to-building-intelligent-workflows-67eeee0899d0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169b046e-6547-4a5c-912d-b90f1236135d",
   "metadata": {},
   "source": [
    "### Messages\n",
    "The messages captures the different roles in the conversation. This is supported by LangChain. \n",
    "\n",
    "- `HumanMessage`: What the user says\n",
    "- `AIMessage`: What the AI says\n",
    "- `SystemMessage`: Instructions for the AI/LLM model (or system prompt)\n",
    "- `ToolMessage`: Output of a tool / function invokation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57a2e3ae-f8e7-4bec-9299-13fa60e4e33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# This loads the .env file for loading api-key\n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e40e522-0252-43ec-8d33-9c960bff1320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: LLM\n",
      "\n",
      "Are you studying about LangGraph?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Aditi\n",
      "\n",
      "Yes\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: LLM\n",
      "\n",
      "What would you want to learn?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Aditi\n",
      "\n",
      "I want to learn about stategraph\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "# \"messages\" variable initialized as a list\n",
    "# 'messages' is list of HumanMessage/AIMessage\n",
    "messages = [AIMessage(content=f'Are you studying about LangGraph?',name='LLM')]                # LLM's question to the user\n",
    "\n",
    "# extend() --> adds elements to the messages list from another list\n",
    "messages.extend([HumanMessage(content=f'Yes', name='Aditi')])                                       # Human's response to LLM \n",
    "messages.extend([AIMessage(content=f'What would you want to learn?',name='LLM')])              # LLM's follow-up question to user \n",
    "messages.extend([HumanMessage(content=f'I want to learn about stategraph', name='Aditi')])          # Human's response to model\n",
    "\n",
    "for msg in messages:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c84b85-9ef0-4751-b663-4d7bbd378195",
   "metadata": {},
   "source": [
    "We will take the list of these messages and will pass it to our chat model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f143406b-0121-4ed1-8212-01501db4885d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StateGraph is a term that can refer to various concepts depending on the context, including computer science, graph theory, and software engineering. In general, it can involve the representation of states and transitions between those states in a graphical format. \n",
      "\n",
      "Here are a few common uses of StateGraph:\n",
      "\n",
      "1. **Finite State Machines (FSMs)**: A StateGraph can represent an FSM, where nodes represent states and edges represent transitions based on inputs or events. This is commonly used in designing protocols, game development, and control systems.\n",
      "\n",
      "2. **State Management in Programming**: In the context of applications, especially single-page applications (SPAs), a StateGraph may represent the different states of the application and how it transitions from one state to another, often used in frameworks like React or Vue.js.\n",
      "\n",
      "3. **Model Checking**: In formal verification, StateGraphs are used to represent the possible states of a system and their transitions, allowing for the analysis of system properties.\n",
      "\n",
      "4. **Process Modeling**: In business process modeling, StateGraphs can help visualize workflows and the various states of a process.\n",
      "\n",
      "If you have a specific context in mind where StateGraph is used, please let me know so I can provide more targeted information!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model='gpt-4o-mini')\n",
    "result = llm.invoke(messages) \n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22f9c74-28a6-4887-ba18-e04f426bf1aa",
   "metadata": {},
   "source": [
    "### Tools (Tool calling by LLMs)\n",
    "When AI Agent needs to interact with an external function / API / model / websearch / access database.\n",
    "\n",
    "- **Tool Creation**: `@tool` decorator to create a tool\n",
    "    - A tool is an association between a Python function and its schema (which describes its purpose and required inputs)\n",
    "- **Tool Binding**:\n",
    "    - The tool needs to be connected to a LLM model that supports tool calling.\n",
    "    - Gives the model awareness of the tool and the associated input schema required by the tool\n",
    "- **Tool Calling**: The model can decide to “call” a tool\n",
    "    - It ensures its response conforms to the tool’s input schema, providing the necessary arguments\n",
    "- **Tool Execution**: Tool can then be executed using the arguments provided by the model\n",
    "    - Output is returned to the model to inform its next response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2e6ea12-6324-4d30-a071-7d901b20332f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 'call_sXqm9EhwrfkuzaP8dk63GTmM', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "# Defining a \"multiply\" tool\n",
    "@tool\n",
    "def multiply(a:int, b:int) ->int:\n",
    "    \"Multiply a and b\"\n",
    "    return a*b\n",
    "\n",
    "# Binding tool with LLM model\n",
    "llm_with_tool = llm.bind_tools([multiply])\n",
    "\n",
    "# Tool call \n",
    "tool_call = llm_with_tool.invoke('what is 2 multiply by 3')\n",
    "# There is no content or \"result\" in AIMessage, but there is a tool call\n",
    "# print(tool_call)\n",
    "\n",
    "# Shows the tool call structure\n",
    "print(tool_call.additional_kwargs['tool_calls']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3c7386-3e3b-445d-8b09-ecf463656762",
   "metadata": {},
   "source": [
    "### Using Messages as State & Reducers\n",
    "In a conversational agent, this is to ensure that each node will not override the message history. Tells LangChain to append new messages as a list.\n",
    "\n",
    "The `add_messages` reducer ensures that when a node returns a `messages` key, its content is appended to the existing list, rather than replacing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bd5f4d9-65ef-4e96-8fbe-fad6cd2c8371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated # adds metadata\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages # Reducer\n",
    "\n",
    "# Tells LangGraph to append messages as list\n",
    "class MessageState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffcbac3-a65c-48c9-8247-cdf0a499e435",
   "metadata": {},
   "source": [
    "### A Graph with MessageState and tool calling\n",
    "- It uses `MessageState` to manage conversation history\n",
    "- It has an LLM node that can decide to call tools\n",
    "- It has a `ToolNode` that executes any tools the LLM requests\n",
    "- It uses a conditional edge (`tools_condition`) to route to the `ToolNode` if the LLM calls a tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c67cee3-f37e-4061-90cd-e68c73582abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages, AnyMessage\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "573c7268-a072-4dc0-ab7e-4b88cba3528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some tools \n",
    "@tool\n",
    "def multiply(a:int, b:int)->int:\n",
    "    \"\"\"this tool will do multiplication\"\"\"\n",
    "    return a*b\n",
    "\n",
    "@tool\n",
    "def add(a:int, b:int) -> int:\n",
    "    \"Add two integers\"\n",
    "    return a+b\n",
    "\n",
    "@tool\n",
    "def subtract(a:int, b:int) -> int:\n",
    "    \"Subtract two integers\"\n",
    "    return a-b\n",
    "    \n",
    "tools_list = [multiply, add, subtract]\n",
    "\n",
    "# Bind tools to your LLM\n",
    "llm_with_tool = ChatOpenAI(model='gpt-4o-mini').bind_tools(tools_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a296fa80-8e60-4acd-9dcd-0fa48fedeeb8",
   "metadata": {},
   "source": [
    "`ToolNode`: LangGraph pre-built class that wraps external tools or functions\n",
    "- Triggered when a tool call is detected\n",
    "- Enables the agent to execute the appropriate function and return the result to the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ab502e5-fd71-4659-a072-5b14ca88bada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the state for our conversational agent\n",
    "class State(TypedDict):\n",
    "    messages : Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "# Define a node for the LLM chatbot\n",
    "def llm_chatbot(state: State):\n",
    "    # Invoke the LLM with the current message history\n",
    "    return {'messages': [llm_with_tool.invoke(state['messages'])]}\n",
    "\n",
    "# ToolNode --> defines the tools as a node\n",
    "# Will run the tools requested by the last AIMessage\n",
    "# If there are multiple tools called, it will run in parallel\n",
    "tool_node = ToolNode(tools_list) # Accepts a list of tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2981ca-a9b7-42fd-95e2-12c6c688dabf",
   "metadata": {},
   "source": [
    "`tools_condition`: pre-built LangGraph function that checks if the last state message includes a tool call\n",
    "- If it does, the flow is routed to the tools node for execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b975a318-3bed-4e05-9d03-2b210ade3376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the StateGraph\n",
    "build = StateGraph(State)\n",
    "# LLM chatbot node\n",
    "build.add_node('LLM', llm_chatbot)\n",
    "# Tool node to execute tools\n",
    "build.add_node('tools', tool_node) \n",
    "\n",
    "# Starting point\n",
    "build.add_edge(START, 'LLM') # Start by sending user input to the LLM\n",
    "\n",
    "# Add a conditional edge from 'LLM'\n",
    "build.add_conditional_edges(\n",
    "    \"LLM\",\n",
    "    tools_condition, # This is a pre-built LangGraph condition: if last message has tool calls, it routes to \"tools\"\n",
    "    # The default mapping for tools_condition is {\"tools\": \"tools_node_name\"}\n",
    ")\n",
    "\n",
    "# After tools run, send results back to the LLM for next turn\n",
    "build.add_edge('tools', 'LLM') \n",
    "\n",
    "# Compile for results\n",
    "app = build.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6b6550-17a6-48f0-aa82-80f76edd7ef5",
   "metadata": {},
   "source": [
    "#### Example Invocations:\n",
    "1. Natural response (LLM directly answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f50cc88-664d-4d50-89ee-caed13c743fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# print(app.invoke({'messages': 'Hi'}))\n",
    "res = app.invoke({'messages': 'Hi'})\n",
    "for r in res['messages']:\n",
    "    r.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adad7c5-80ea-4b5a-a716-ef37eb6b416e",
   "metadata": {},
   "source": [
    "2. Tool response (LLM calls tools, then provides an answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0068fb41-db4d-4087-938d-0fab04cb1e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "first tell me some things about Boston. Second calculate 10+2\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Boston is the capital city of Massachusetts and is one of the oldest cities in the United States, founded in 1630. Here are some key points about Boston:\n",
      "\n",
      "1. **History**: Boston played a significant role in American history, especially during the American Revolution, with events such as the Boston Massacre and the Boston Tea Party.\n",
      "\n",
      "2. **Education**: The city is known for its prestigious universities and colleges, including Harvard University and the Massachusetts Institute of Technology (MIT), both located in the Greater Boston area.\n",
      "\n",
      "3. **Culture**: Boston has a rich cultural scene, with numerous museums, theaters, and historical sites. The Boston Symphony Orchestra and Boston Museum of Fine Arts are notable institutions.\n",
      "\n",
      "4. **Sports**: Boston is home to several major sports teams, including the Red Sox (MLB), Celtics (NBA), and Bruins (NHL), and has a passionate sports culture.\n",
      "\n",
      "5. **Economy**: The city has a diverse economy, with strengths in finance, healthcare, education, and technology.\n",
      "\n",
      "6. **Innovation**: Boston is often recognized as a hub for innovation and entrepreneurship, particularly in the fields of biotechnology and healthcare.\n",
      "\n",
      "Now, let's calculate \\(10 + 2\\).\n",
      "Tool Calls:\n",
      "  add (call_D3T8bTtRO6sW2ecnfW74vgGB)\n",
      " Call ID: call_D3T8bTtRO6sW2ecnfW74vgGB\n",
      "  Args:\n",
      "    a: 10\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "12\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of \\(10 + 2\\) is \\(12\\).\n"
     ]
    }
   ],
   "source": [
    "msg = app.invoke({'messages': \"first tell me some things about Boston. Second calculate 10+2\"})\n",
    "for m in msg['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3137604-3ca5-47f1-ac03-d01778a48e61",
   "metadata": {},
   "source": [
    "**NOTE**: Expected output will show AI messages, tool call messages, and then the final AI response, combining the search result and the calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f4c00b-2e84-46e5-a19b-34a85d51ec08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
